# Working with containers on LUMI

Machine learning frameworks on LUMI are served as isolated environments in a form of container images with fundametal set of Python packages. LUMI uses the [Singularity](https://docs.sylabs.io/guides/main/user-guide/) (SingularityCE) container runtime.

Containers can be seen as encapsulated images of a specific environment including all libraries and tools and most importantly python packages. Container image can be based on virtually any linux distribution targeting host architecture but it still relies on host kernel and kernel drivers. This plays significant role in the case of LUMI.

## Base containers

The motivation for using base containers is twofold: 

 - compatibility with ROCm (GPU runtime) and Slingshot network (inter-node communication), 
 - filesystem friendliness (encapsulation limits filesystem load generated by accessing many small files).

Althouht this implies base images are not portable which is usually expected from containers. These images unlikely run on other systems. 

Base images are available as flat sif files stored on the shared filesystem (image registry is not provided).

Naming of the sif files follows the convention: 

```
lumi-package_name-rocm-rocm_version-python-python_version-package_name-package_version-dockerhash-docker_hash.sif
``` 

with available combinations from the following table:

| Package name | ROCm version | Python version | Package version | Docker hash | 
| --- | --- | --- | --- | --- | 
|  `mpi4py` | `6.2.0` | `3.12` | `3.1.6` | `f049c8bd4669` |
| --- | --- | --- | --- | --- | 
| `pytorch` | `5.7.3` | `3.12` | `v2.2.2` | `b0bb3b4ea779` |
| `pytorch` | `6.2.0` | `3.10` | `v2.3.0` | `187f41102477` |
| `pytorch` | `6.0.3` | `3.12` | `v2.3.1` | `2c1c14cafd28` |
| `pytorch` | `6.1.3` | `3.12` | `v2.4.1` | `04f2083a6cb0` |
| `pytorch` | `6.2.1` | `3.12` | `20240918-vllm-4075b35` | `3cad1babc4b8` |


## Interacting with a containerized environment

Python environment from an image can be accesed either interactively with spawning a shell instance within a container (`sinularity shell` command) or by executing command within a container (`singularity exec` command). Do not expert actual runscript, you need to execute your own script. There are also common assuptions used:

 - most of base images on LUMI uses conda (Miniconda) environments that need to be activated with `$WITH_CONDA` alias command,
 - there is basic compiler toolchain included, note specific compiler commands (`gcc-XX` for scpefic versions installed).

## Singularity and Slurm

Most of the time container executeis on a compute node same way as regular program is. You need to prepend singularity command with `srun` launcher; plese note multiple srun tasks will spawn independent instances of the same container image. 

## Installing additional packages in a container 

### Using cotainr tool to extend existing image

## Custom images

User can also bring own container image or convert image from registry (DockerHub for instance) to singularity format.
